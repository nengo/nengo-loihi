{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 convolutional network\n",
    "\n",
    "This is a small CIFAR-10 convolutional neural network designed to run on one\n",
    "Loihi chip. Because of these size constraints, it is not particularly\n",
    "powerful, and does not achieve anywhere near state-of-the-art results on the\n",
    "task. Nevertheless, the network performs well enough to demonstrate that\n",
    "Loihi is capable of hosting larger, more powerful object recognition networks\n",
    "than MNIST.\n",
    "\n",
    "The main libraries we'll be using in this tutorial are:\n",
    "\n",
    "- `nengo` to create the network\n",
    "- `nengo_dl` to train the network (`nengo_dl` uses `tensorflow` under the hood, so we\n",
    "also import that, along with the `tensorflow_probability` extension package, to define\n",
    "the loss function)\n",
    "- `nengo_loihi` to run the network on the Loihi hardware (or simulate Loihi if hardware\n",
    "is not available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "from functools import partial\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import nengo_loihi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "First, we'll make some preliminary definitions\n",
    "that will help us throughout the rest of the training process.\n",
    "Understanding these in detail is not necessary to understand the example,\n",
    "so feel free to skip them and come back later, or ignore them completely.\n",
    "\n",
    "We define a function called `percentile_l2_loss_range`,\n",
    "which we will use to help regularize our neuron firing rates\n",
    "so that they fall in our desired range.\n",
    "The input `y` to our function is the firing rates of all neurons\n",
    "across all examples in the batch.\n",
    "We compute a percentile on these firing rates for each neuron,\n",
    "across all the examples.\n",
    "If this percentile is outside our desired range of `min` to `max`,\n",
    "then it contributes to the squared loss.\n",
    "\n",
    "`slice_data_dict` applies a slice to the first dimension\n",
    "of all arrays in a data dictionary,\n",
    "to make it easy to select a subset of data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_l2_loss_range(\n",
    "    y_true, y, sample_weight=None, min_rate=0.0, max_rate=np.inf, percentile=99.0\n",
    "):\n",
    "    # y axes are (batch examples, time (==1), neurons)\n",
    "    assert len(y.shape) == 3\n",
    "    rates = tfp.stats.percentile(y, percentile, axis=(0, 1))\n",
    "    low_error = tf.maximum(0.0, min_rate - rates)\n",
    "    high_error = tf.maximum(0.0, rates - max_rate)\n",
    "    loss = tf.nn.l2_loss(low_error + high_error)\n",
    "\n",
    "    return (sample_weight * loss) if sample_weight is not None else loss\n",
    "\n",
    "\n",
    "def slice_data_dict(data, slice_):\n",
    "    return {key: value[slice_] for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a custom class for iterating an image dataset and returning dictionaries\n",
    "that can be used by NengoDL for training. Much of this is a re-implementation of\n",
    "`tf.keras.preprocessing.image.NumpyArrayIterator`, with the additional features of (a)\n",
    "allowing us to return dictionaries with the provided keys, rather than just lists of\n",
    "Numpy arrays, and (b) allowing multiple `y` values to be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NengoImageIterator(tf.keras.preprocessing.image.Iterator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_data_generator,\n",
    "        x_keys,\n",
    "        x,\n",
    "        y_keys,\n",
    "        y,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        sample_weight=None,\n",
    "        seed=None,\n",
    "        subset=None,\n",
    "        dtype=\"float32\",\n",
    "    ):\n",
    "        assert subset is None, \"Not Implemented\"\n",
    "        assert isinstance(x_keys, (tuple, list))\n",
    "        assert isinstance(y_keys, (tuple, list))\n",
    "        assert isinstance(x, (tuple, list))\n",
    "        assert isinstance(y, (tuple, list))\n",
    "\n",
    "        self.dtype = dtype\n",
    "        self.x_keys = x_keys\n",
    "        self.y_keys = y_keys\n",
    "\n",
    "        x0 = x[0]\n",
    "        assert all(len(xx) == len(x0) for xx in x), (\n",
    "            \"All of the arrays in `x` should have the same length. \"\n",
    "            \"[len(xx) for xx in x] = %s\" % ([len(xx) for xx in x],)\n",
    "        )\n",
    "        assert all(len(yy) == len(x0) for yy in y), (\n",
    "            \"All of the arrays in `y` should have the same length as `x`. \"\n",
    "            \"len(x[0]) = %d, [len(yy) for yy in y] = %s\"\n",
    "            % (len(x0), [len(yy) for yy in y])\n",
    "        )\n",
    "        assert len(x_keys) == len(x)\n",
    "        assert len(y_keys) == len(y)\n",
    "\n",
    "        if sample_weight is not None and len(x0) != len(sample_weight):\n",
    "            raise ValueError(\n",
    "                \"`x[0]` (images tensor) and `sample_weight` \"\n",
    "                \"should have the same length. \"\n",
    "                \"Found: x.shape = %s, sample_weight.shape = %s\"\n",
    "                % (np.asarray(x0).shape, np.asarray(sample_weight).shape)\n",
    "            )\n",
    "\n",
    "        self.x = [\n",
    "            np.asarray(xx, dtype=self.dtype if i == 0 else None)\n",
    "            for i, xx in enumerate(x)\n",
    "        ]\n",
    "        if self.x[0].ndim != 4:\n",
    "            raise ValueError(\n",
    "                \"Input data in `NumpyArrayIterator` \"\n",
    "                \"should have rank 4. You passed an array \"\n",
    "                \"with shape\",\n",
    "                self.x[0].shape,\n",
    "            )\n",
    "\n",
    "        self.y = [np.asarray(yy) for yy in y]\n",
    "        self.sample_weight = (\n",
    "            None if sample_weight is None else np.asarray(sample_weight)\n",
    "        )\n",
    "        self.image_data_generator = image_data_generator\n",
    "        super().__init__(self.x[0].shape[0], batch_size, shuffle, seed)\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        images = self.x[0]\n",
    "        assert images.dtype == self.dtype\n",
    "\n",
    "        n = len(index_array)\n",
    "        batch_x = np.zeros((n,) + images[0].shape, dtype=self.dtype)\n",
    "        for i, j in enumerate(index_array):\n",
    "            x = images[j]\n",
    "            params = self.image_data_generator.get_random_transform(x.shape)\n",
    "            x = self.image_data_generator.apply_transform(x, params)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "\n",
    "        batch_x_miscs = [xx[index_array] for xx in self.x[1:]]\n",
    "        batch_y_miscs = [yy[index_array] for yy in self.y]\n",
    "\n",
    "        x_pairs = [\n",
    "            (k, self.x_postprocess(k, v))\n",
    "            for k, v in zip(self.x_keys, [batch_x] + batch_x_miscs)\n",
    "        ]\n",
    "        y_pairs = [\n",
    "            (k, self.y_postprocess(k, v)) for k, v in zip(self.y_keys, batch_y_miscs)\n",
    "        ]\n",
    "\n",
    "        output = (\n",
    "            collections.OrderedDict(x_pairs),\n",
    "            collections.OrderedDict(y_pairs),\n",
    "        )\n",
    "\n",
    "        if self.sample_weight is not None:\n",
    "            output += (self.sample_weight[index_array],)\n",
    "        return output\n",
    "\n",
    "    def x_postprocess(self, key, x):\n",
    "        return x if key == \"n_steps\" else x.reshape((x.shape[0], 1, -1))\n",
    "\n",
    "    def y_postprocess(self, key, y):\n",
    "        return y.reshape((y.shape[0], 1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "We load the CIFAR-10 dataset using TensorFlow.\n",
    "The data comes as `numpy.uint8` values in the range [0, 255],\n",
    "so we rescale the data to the range [-1, 1].\n",
    "We create one-hot representations of the labels to use during training,\n",
    "as well as \"flat\" versions of the data where the images are flattened into vectors.\n",
    "Finally, we define an `input_shape` object that describes the image shape\n",
    "in a format that Nengo can use.\n",
    "\n",
    "One variable that occurs a number of times here is the `channels_last` option,\n",
    "which can be set to `True` or `False`.\n",
    "This option dictates whether the image (color) channels are stored\n",
    "as the last (i.e. least-significant) index in each image (`True`),\n",
    "or the first (i.e. most-significant) index (`False`).\n",
    "This will also dictate how the images will be represented on Loihi,\n",
    "and can have effects on the number of axons and weights required on the chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_last = True\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "n_classes = len(np.unique(train_y))\n",
    "\n",
    "# TensorFlow does not include the label names, so define them manually\n",
    "label_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "assert n_classes == len(label_names)\n",
    "\n",
    "if not channels_last:\n",
    "    train_x = np.transpose(train_x, (0, 3, 1, 2))\n",
    "    test_x = np.transpose(test_x, (0, 3, 1, 2))\n",
    "\n",
    "# convert the images to float32, and rescale to [-1, 1]\n",
    "train_x = train_x.astype(np.float32) / 127.5 - 1\n",
    "test_x = test_x.astype(np.float32) / 127.5 - 1\n",
    "\n",
    "train_t = np.array(tf.one_hot(train_y, n_classes), dtype=np.float32)\n",
    "test_t = np.array(tf.one_hot(test_y, n_classes), dtype=np.float32)\n",
    "\n",
    "train_y = train_y.squeeze()\n",
    "test_y = test_y.squeeze()\n",
    "\n",
    "train_x_flat = train_x.reshape((train_x.shape[0], 1, -1))\n",
    "train_t_flat = train_t.reshape((train_t.shape[0], 1, -1))\n",
    "\n",
    "test_x_flat = test_x.reshape((test_x.shape[0], 1, -1))\n",
    "test_t_flat = test_t.reshape((test_t.shape[0], 1, -1))\n",
    "\n",
    "input_shape = nengo.transforms.ChannelShape(\n",
    "    test_x[0].shape, channels_last=channels_last\n",
    ")\n",
    "assert input_shape.n_channels in (1, 3)\n",
    "assert train_x[0].shape == test_x[0].shape == input_shape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Nengo Network\n",
    "\n",
    "Next, we create the Nengo network that we will train to classify the data.\n",
    "\n",
    "First, we specify some configuration parameters:\n",
    "- `max_rate` is the target maximum firing rate for all ensembles.\n",
    "  We pick 150 because above 150 Hz, the quantization error in\n",
    "  Loihi neurons becomes significant.\n",
    "- The amplitude of our neurons is chosen as `1 / max_rate`,\n",
    "  so that neuron outputs are generally between 0 and 1;\n",
    "  this helps to match the scaling of the initial weights.\n",
    "- `rate_reg` is the amount of regularization on the firing rates.\n",
    "  We pick it empirically to be\n",
    "  high enough to achieve the desired firing rates during training,\n",
    "  and low enough to not have a significant adverse effect on accuracy.\n",
    "- The `rate_target` is the target value used in the loss functions;\n",
    "  it includes the amplitude scaling, since the neuron outputs received\n",
    "  by the loss functions will also include the amplitude scaling.\n",
    "\n",
    "We also define two neuron types we will use in our model.\n",
    "One is a standard `nengo.SpikingRectifiedLinear` neuron,\n",
    "which we use for our input neurons that are run off-chip.\n",
    "The other is a `LoihiLIF` neuron type, used for the on-chip neurons.\n",
    "This type takes into account the quantization error in Loihi neurons,\n",
    "so by training with this neuron type in NengoDL,\n",
    "our model is better able to deal with the quantization error.\n",
    "\n",
    "To simplify the configuration,\n",
    "we define the configurable layer parameters in a list of dictionaries\n",
    "called `layer_confs`.\n",
    "When we create the network, we loop through these entries,\n",
    "and create one layer for each dictionary.\n",
    "\n",
    "The Nengo network has three main parts:\n",
    "\n",
    "1. Input neurons that are run off-chip to turn the input into spikes.\n",
    "   This is the first entry in `layer_confs`.\n",
    "   It is a 1x1 convolutional layer with 4 filters,\n",
    "   meaning that for each pixel (which has 3 color values),\n",
    "   it will apply a (learned) linear transform to turn those\n",
    "   3 values into 4 values,\n",
    "   and then pass that into `SpikingRectifiedLinear` neurons\n",
    "   to generate spikes.\n",
    "   The reason we don't just use the raw color channels is that\n",
    "   they can have both positive and negative values,\n",
    "   and we would have to figure out a way to transform them\n",
    "   to work with firing rates that can only have positive values.\n",
    "   One possible transform would be to use an on/off neuron pair\n",
    "   to represent each pixel,\n",
    "   resulting in 6 neurons per pixel.\n",
    "   Rather than force this specific encoding, though,\n",
    "   we find it easier to let the system learn the encoding via\n",
    "   the 1x1 convolutional layer.\n",
    "   We could use a higher maximum firing rate for neurons in this layer\n",
    "   (up to `1 / dt`, where `dt` is the simulation timestep),\n",
    "   because these neurons are simulated off-chip and thus not subject\n",
    "   to the same quantization error as on-chip neurons.\n",
    "2. Convolutional and dense neural layers that are run on the chip (Loihi).\n",
    "   We specify these as in a normal convolutional neural network,\n",
    "   with any entry that begins with a `filters` parameter\n",
    "   describing a convolutional layer,\n",
    "   and any entry that begins with an `n_neurons` parameter\n",
    "   describing a dense layer.\n",
    "   One special parameter that we have is the `block` parameter.\n",
    "   This describes the size of representation that will\n",
    "   go on one \"block\" (i.e. Loihi core),\n",
    "   in `(rows, columns, channels)` format.\n",
    "   Loihi cores are limited to 1024 neurons,\n",
    "   so the product of the rows, columns, and channels must be `<= 1024`.\n",
    "   We also choose the block shape to minimize\n",
    "   the number of input and output axons to and from each core\n",
    "   (since these are also constrained on Loihi).\n",
    "   Multiple filters on a core can use the same axons,\n",
    "   so we try to increase the number of filters per core.\n",
    "   One approach is to have each layer represent\n",
    "   the entire spacial extent of the image,\n",
    "   but only a fraction of the filters.\n",
    "   For this network, we found that this approach was creating too many\n",
    "   output axons in earlier layers in the network,\n",
    "   so we decided to also split the image spatially.\n",
    "   For example, in the first layer on the chip\n",
    "   (the second entry in `layer_confs`),\n",
    "   the shape of the image being represented is `(15, 15, 64)`\n",
    "   (that is, 15 rows and columns, and 64 channels).\n",
    "   We make the block shape `(8, 8, 8)`,\n",
    "   which means that blocks will have to be tiled twice\n",
    "   both row-wise and column-wise to represent the spatial extent of the image.\n",
    "   However, the number of times we have to tile blocks\n",
    "   in the channel direction (to cover all 64 channels)\n",
    "   goes down, as compared with e.g. a block size of `(15, 15, 4)`,\n",
    "   and the number of axons is reduced. More information on configuring the\n",
    "   block size can be found\n",
    "   [here](https://www.nengo.ai/nengo-loihi/tips.html#splitting-large-ensembles).\n",
    "3. The final part of the network is the last layer, which collects the output.\n",
    "   Like the first layer, it runs off-chip,\n",
    "   and allows us to get data off the board.\n",
    "   We have intentionally made the layer right before it\n",
    "   (the last layer on the chip) only have 100 neurons,\n",
    "   so that we only have to record from 100 neurons to get data off the chip.\n",
    "\n",
    "As we create each layer in the network,\n",
    "we print some information about the layer,\n",
    "which is shown as the output to this code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rate = 150\n",
    "amp = 1.0 / max_rate\n",
    "rate_reg = 1e-3\n",
    "rate_target = max_rate * amp  # must be in amplitude scaled units\n",
    "\n",
    "relu = nengo.SpikingRectifiedLinear(amplitude=amp)\n",
    "chip_neuron = nengo_loihi.neurons.LoihiLIF(amplitude=amp)\n",
    "\n",
    "layer_confs = [\n",
    "    dict(\n",
    "        name=\"input-layer\",\n",
    "        filters=4,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        neuron=relu,\n",
    "        on_chip=False,\n",
    "    ),\n",
    "    dict(name=\"conv-layer1\", filters=64, kernel_size=3, strides=2, block=(8, 8, 16)),\n",
    "    dict(name=\"conv-layer2\", filters=72, kernel_size=3, strides=1, block=(7, 7, 8)),\n",
    "    dict(name=\"conv-layer3\", filters=256, kernel_size=3, strides=2, block=(6, 6, 12)),\n",
    "    dict(name=\"conv-layer4\", filters=256, kernel_size=1, strides=1, block=(6, 6, 24)),\n",
    "    dict(name=\"conv-layer5\", filters=64, kernel_size=1, strides=1, block=(6, 6, 24)),\n",
    "    dict(name=\"dense-layer\", n_neurons=100, block=(50,)),\n",
    "    dict(name=\"output-layer\", n_neurons=10, neuron=None, on_chip=False),\n",
    "]\n",
    "\n",
    "# Create a PresentInput process to show images from the training set sequentially.\n",
    "# Each image is presented for `presentation_time` seconds.\n",
    "# NOTE: this is not used during training, since we get `nengo_dl` to override the\n",
    "# output of this node with the training data.\n",
    "presentation_time = 0.2\n",
    "present_images = nengo.processes.PresentInput(test_x_flat, presentation_time)\n",
    "\n",
    "total_n_neurons = 0\n",
    "total_n_weights = 0\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    net.config[nengo.Ensemble].max_rates = nengo.dists.Choice([max_rate])\n",
    "    net.config[nengo.Ensemble].intercepts = nengo.dists.Choice([0])\n",
    "    net.config[nengo.Connection].synapse = None\n",
    "\n",
    "    # add a configurable keep_history option to Probes (we'll set this\n",
    "    # to False for some probes below)\n",
    "    nengo_dl.configure_settings(keep_history=True)\n",
    "\n",
    "    # this is an optimization to improve the training speed,\n",
    "    # since we won't require stateful behaviour in this example\n",
    "    nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    # this sets the amount of smoothing used on the LIF neurons during training\n",
    "    nengo_dl.configure_settings(lif_smoothing=0.01)\n",
    "\n",
    "    # this allows us to set `nengo_loihi` parameters like `on_chip` and `block_shape`\n",
    "    nengo_loihi.add_params(net)\n",
    "\n",
    "    # the input node that will be used to feed in input images\n",
    "    inp = nengo.Node(present_images, label=\"input_node\")\n",
    "\n",
    "    connections = []\n",
    "    transforms = []\n",
    "    layer_probes = []\n",
    "    shape_in = input_shape\n",
    "    x = inp\n",
    "    for k, layer_conf in enumerate(layer_confs):\n",
    "        layer_conf = dict(layer_conf)  # copy, so we don't modify the original\n",
    "        name = layer_conf.pop(\"name\")\n",
    "        neuron_type = layer_conf.pop(\"neuron\", chip_neuron)\n",
    "        on_chip = layer_conf.pop(\"on_chip\", True)\n",
    "        block = layer_conf.pop(\"block\", None)\n",
    "\n",
    "        if block is not None and not channels_last:\n",
    "            # move channels to first index\n",
    "            block = (block[-1],) + block[:-1]\n",
    "\n",
    "        # --- create layer transform\n",
    "        if \"filters\" in layer_conf:\n",
    "            # convolutional layer\n",
    "            n_filters = layer_conf.pop(\"filters\")\n",
    "            kernel_size = layer_conf.pop(\"kernel_size\")\n",
    "            strides = layer_conf.pop(\"strides\", 1)\n",
    "            assert len(layer_conf) == 0, \"Unused fields in conv layer: %s\" % list(\n",
    "                layer_conf\n",
    "            )\n",
    "\n",
    "            kernel_size = (\n",
    "                (kernel_size, kernel_size)\n",
    "                if isinstance(kernel_size, int)\n",
    "                else kernel_size\n",
    "            )\n",
    "            strides = (strides, strides) if isinstance(strides, int) else strides\n",
    "\n",
    "            transform = nengo.Convolution(\n",
    "                n_filters=n_filters,\n",
    "                input_shape=shape_in,\n",
    "                kernel_size=kernel_size,\n",
    "                strides=strides,\n",
    "                padding=\"valid\",\n",
    "                channels_last=channels_last,\n",
    "                init=nengo_dl.dists.Glorot(scale=1.0 / np.prod(kernel_size)),\n",
    "            )\n",
    "            shape_out = transform.output_shape\n",
    "\n",
    "            loc = \"chip\" if on_chip else \"host\"\n",
    "            n_neurons = np.prod(shape_out.shape)\n",
    "            n_weights = np.prod(transform.kernel_shape)\n",
    "            print(\n",
    "                \"%s: %s: conv %s, stride %s, output %s (%d neurons, %d weights)\"\n",
    "                % (\n",
    "                    loc,\n",
    "                    name,\n",
    "                    kernel_size,\n",
    "                    strides,\n",
    "                    shape_out.shape,\n",
    "                    n_neurons,\n",
    "                    n_weights,\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # dense layer\n",
    "            n_neurons = layer_conf.pop(\"n_neurons\")\n",
    "\n",
    "            shape_out = nengo.transforms.ChannelShape((n_neurons,))\n",
    "            transform = nengo.Dense(\n",
    "                (shape_out.size, shape_in.size),\n",
    "                init=nengo_dl.dists.Glorot(),\n",
    "            )\n",
    "\n",
    "            loc = \"chip\" if on_chip else \"host\"\n",
    "            n_weights = np.prod(transform.shape)\n",
    "            print(\n",
    "                \"%s: %s: dense %d, output %s (%d neurons, %d weights)\"\n",
    "                % (loc, name, n_neurons, shape_out.shape, n_neurons, n_weights)\n",
    "            )\n",
    "\n",
    "        assert len(layer_conf) == 0, \"Unused fields in %s: %s\" % (\n",
    "            [name] + list(layer_conf)\n",
    "        )\n",
    "\n",
    "        total_n_neurons += n_neurons\n",
    "        total_n_weights += n_weights\n",
    "\n",
    "        # --- create layer output (Ensemble or Node)\n",
    "        assert on_chip or block is None, \"`block` must be None if off-chip\"\n",
    "\n",
    "        if neuron_type is None:\n",
    "            assert not on_chip, \"Nodes can only be run off-chip\"\n",
    "            y = nengo.Node(size_in=shape_out.size, label=name)\n",
    "        else:\n",
    "            ens = nengo.Ensemble(shape_out.size, 1, neuron_type=neuron_type, label=name)\n",
    "            net.config[ens].on_chip = on_chip\n",
    "            y = ens.neurons\n",
    "\n",
    "            if block is not None:\n",
    "                net.config[ens].block_shape = nengo_loihi.BlockShape(\n",
    "                    block,\n",
    "                    shape_out.shape,\n",
    "                )\n",
    "\n",
    "            # add a probe so we can measure individual layer rates\n",
    "            probe = nengo.Probe(y, synapse=None, label=\"%s_p\" % name)\n",
    "            net.config[probe].keep_history = False\n",
    "            layer_probes.append(probe)\n",
    "\n",
    "        conn = nengo.Connection(x, y, transform=transform)\n",
    "        net.config[conn].pop_type = 32\n",
    "\n",
    "        transforms.append(transform)\n",
    "        connections.append(conn)\n",
    "        x = y\n",
    "        shape_in = shape_out\n",
    "\n",
    "    output_p = nengo.Probe(x, synapse=None, label=\"output_p\")\n",
    "\n",
    "print(\"TOTAL: %d neurons, %d weights\" % (total_n_neurons, total_n_weights))\n",
    "assert len(layer_confs) == len(transforms) == len(connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network using NengoDL\n",
    "\n",
    "First, we check the output of all layers with the initial parameters. This helps us to\n",
    "tell whether the layers have been initialized well, or if we need to fine-tune the\n",
    "initialization parameters a bit more (for example, by changing their magnitudes\n",
    "slightly). Layers that have zero (or very small) output, or very large output, are\n",
    "red-flags that the initialization is not good, and training may not progress well.\n",
    "\n",
    "We use `tf.keras.backend.learning_phase_scope(1)` to make sure that the simulator always\n",
    "runs our neurons in rate mode (as opposed to spiking mode), allowing us to evaluate the\n",
    "network as an ANN. We will only use spiking neurons when we run the network on Loihi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input and target dictionaries to pass to NengoDL\n",
    "train_inputs = {inp: train_x_flat}\n",
    "train_targets = {output_p: train_t_flat}\n",
    "\n",
    "test_inputs = {inp: test_x_flat}\n",
    "test_targets = {output_p: test_t_flat}\n",
    "for probe in layer_probes:\n",
    "    train_targets[probe] = np.zeros((train_t_flat.shape[0], 1, 0), dtype=np.float32)\n",
    "    test_targets[probe] = np.zeros((test_t_flat.shape[0], 1, 0), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- evaluate layers\n",
    "# use rate neurons always by setting learning_phase_scope\n",
    "with tf.keras.backend.learning_phase_scope(1), nengo_dl.Simulator(\n",
    "    net, minibatch_size=100, progress_bar=False\n",
    ") as sim:\n",
    "    for conf, conn in zip(layer_confs, connections):\n",
    "        weights = sim.model.sig[conn][\"weights\"].initial_value\n",
    "        print(\"%s: initial weights: %0.3f\" % (conf[\"name\"], np.abs(weights).mean()))\n",
    "\n",
    "    sim.run_steps(1, data={inp: train_x_flat[:100]})\n",
    "\n",
    "for conf, layer_probe in zip(layer_confs, layer_probes):\n",
    "    out = sim.data[layer_probe][-1]\n",
    "    print(\"%s: initial rates: %0.3f\" % (conf[\"name\"], np.mean(out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since everything looks good, we go ahead and train with NengoDL.\n",
    "\n",
    "We create an `ImageDataGenerator` that will generate augmented (shifted, rotated, and\n",
    "flipped) versions of the data.\n",
    "\n",
    "We define our loss function and metrics. Our loss function has one entry for the output\n",
    "probe (`output_p`) that computes the cross-entropy on our outputs (to reduce our\n",
    "classification error), and entries for each of our layer rate outputs (`layer_probes`)\n",
    "that push the layer firing rates to their target ranges. The total loss is the sum of\n",
    "all these individual losses.\n",
    "\n",
    "Our metrics are organized in the same way as our losses. We measure classification error\n",
    "for our output, and the 99.9th percentile firing rate for each neuron. These metrics\n",
    "will be printed during training, so that we can track accuracy and firing rates to make\n",
    "sure training is progressing as expected.\n",
    "\n",
    "To speed up this example we have provided some pre-trained weights that will be\n",
    "downloaded. Set `do_training = True` to run the training yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = False\n",
    "\n",
    "checkpoint_base = \"./cifar10_convnet_params\"\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_idg = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    data_format=\"channels_last\" if channels_last else \"channels_first\",\n",
    ")\n",
    "train_idg.fit(train_x)\n",
    "\n",
    "# use rate neurons always by setting learning_phase_scope\n",
    "with tf.keras.backend.learning_phase_scope(1), nengo_dl.Simulator(\n",
    "    net, minibatch_size=batch_size\n",
    ") as sim:\n",
    "\n",
    "    percentile = 99.9\n",
    "\n",
    "    def rate_metric(_, outputs):\n",
    "        # take percentile over all examples, for each neuron\n",
    "        top_rates = tfp.stats.percentile(outputs, percentile, axis=(0, 1))\n",
    "        return tf.reduce_mean(top_rates) / amp\n",
    "\n",
    "    losses = collections.OrderedDict()\n",
    "    metrics = collections.OrderedDict()\n",
    "    loss_weights = collections.OrderedDict()\n",
    "\n",
    "    losses[output_p] = tf.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    metrics[output_p] = \"accuracy\"\n",
    "    loss_weights[output_p] = 1.0\n",
    "\n",
    "    for probe, layer_conf in zip(layer_probes, layer_confs):\n",
    "        metrics[probe] = rate_metric\n",
    "\n",
    "        if layer_conf.get(\"on_chip\", True):\n",
    "            losses[probe] = partial(\n",
    "                percentile_l2_loss_range,\n",
    "                min_rate=0.5 * rate_target,\n",
    "                max_rate=rate_target,\n",
    "                percentile=percentile,\n",
    "            )\n",
    "            loss_weights[probe] = rate_reg\n",
    "        else:\n",
    "            losses[probe] = partial(\n",
    "                percentile_l2_loss_range,\n",
    "                min_rate=0,\n",
    "                max_rate=rate_target,\n",
    "                percentile=percentile,\n",
    "            )\n",
    "            loss_weights[probe] = 10 * rate_reg\n",
    "\n",
    "    sim.compile(\n",
    "        loss=losses,\n",
    "        optimizer=tf.optimizers.Adam(),\n",
    "        metrics=metrics,\n",
    "        loss_weights=loss_weights,\n",
    "    )\n",
    "\n",
    "    if do_training:\n",
    "        # --- train\n",
    "        steps_per_epoch = len(train_x) // batch_size\n",
    "\n",
    "        # Create a NengoImageIterator that will return the appropriate dictionaries\n",
    "        # with augmented images. Since we are using a generator, we need to include\n",
    "        # the `n_steps` parameter so that NengoDL knows how many timesteps are in\n",
    "        # each example (in our case, since we just have static images, it's one).\n",
    "        n = steps_per_epoch * batch_size\n",
    "        n_steps = np.ones((n, 1), dtype=np.int32)\n",
    "        train_data = NengoImageIterator(\n",
    "            image_data_generator=train_idg,\n",
    "            x_keys=[inp.label, \"n_steps\"],\n",
    "            x=[train_x[:n], n_steps],\n",
    "            y_keys=[output_p.label] + [probe.label for probe in layer_probes],\n",
    "            y=[train_t[:n]]\n",
    "            + [np.zeros((n, 1, 0), dtype=np.float32) for _ in layer_probes],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        n_epochs = 100\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            sim.fit(\n",
    "                train_data,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs=1,\n",
    "                verbose=2,\n",
    "            )\n",
    "\n",
    "            # report test data statistics\n",
    "            outputs = sim.evaluate(x=test_inputs, y=test_targets, verbose=0)\n",
    "            print(\"Epoch %d test: %s\" % (epoch, outputs))\n",
    "\n",
    "            # save the parameters to the checkpoint\n",
    "            savefile = checkpoint_base\n",
    "            sim.save_params(savefile)\n",
    "            print(\"Saved params to %r\" % savefile)\n",
    "    else:\n",
    "        urlretrieve(\n",
    "            \"https://drive.google.com/uc?export=download&\"\n",
    "            \"id=1jvP8IsdqGH2kn0OJOykJxjBsJLgk8GsY\",\n",
    "            \"%s.npz\" % checkpoint_base,\n",
    "        )\n",
    "        sim.load_params(checkpoint_base)\n",
    "        print(\"Loaded params %r\" % checkpoint_base)\n",
    "\n",
    "    # copy the learned/loaded parameters back to the network, for Loihi simulator\n",
    "    sim.freeze_params(net)\n",
    "\n",
    "    # run the network on some of the train and test data to benchmark performance\n",
    "    try:\n",
    "        train_slice = slice(0, 1000)\n",
    "        train_outputs = sim.evaluate(\n",
    "            x=slice_data_dict(train_inputs, train_slice),\n",
    "            y=slice_data_dict(train_targets, train_slice),\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(\"Final train:\")\n",
    "        for key, val in train_outputs.items():\n",
    "            print(\"  %s: %s\" % (key, val))\n",
    "\n",
    "        # test_slice = slice(None)\n",
    "        test_slice = slice(0, 1000)\n",
    "        test_outputs = sim.evaluate(\n",
    "            x=slice_data_dict(test_inputs, test_slice),\n",
    "            y=slice_data_dict(test_targets, test_slice),\n",
    "            verbose=0,\n",
    "        )\n",
    "        print(\"Final test:\")\n",
    "        for key, val in test_outputs.items():\n",
    "            print(\"  %s: %s\" % (key, val))\n",
    "    except Exception as e:\n",
    "        print(\"Could not compute ANN values on this machine: %s\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the spiking neural network on Loihi\n",
    "\n",
    "Now, we run the spiking model on Loihi\n",
    "(or in the emulator if ``nxsdk`` is not installed).\n",
    "For demonstration purposes, we only run 10 examples,\n",
    "but feel free to run 100 or more examples\n",
    "if you wish to get a better idea of the network accuracy.\n",
    "\n",
    "The first thing we do is remove the probes on the individual layers.\n",
    "This is because probing neurons takes resources on Loihi,\n",
    "and we cannot afford to probe all the neurons in the model.\n",
    "The probe on the output layer will remain;\n",
    "this is how we will get our results.\n",
    "\n",
    "We also add synapses to all our connections.\n",
    "This provides some filtering,\n",
    "to help deal with the variability introduced\n",
    "when we switch to using spiking neurons.\n",
    "\n",
    "Before running the network,\n",
    "we print some information about the blocks that have been created.\n",
    "One block corresponds to one Loihi core,\n",
    "so this gives us information about how much each core is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove layer probes\n",
    "for probe in layer_probes:\n",
    "    if probe in net.probes:\n",
    "        net.probes.remove(probe)\n",
    "\n",
    "# add synapses to connections\n",
    "for conn in net.all_connections:\n",
    "    conn.synapse = nengo.synapses.Lowpass(0.01)\n",
    "\n",
    "n_images = 10\n",
    "\n",
    "sim_time = n_images * presentation_time\n",
    "\n",
    "with nengo_loihi.Simulator(net) as sim:\n",
    "    # print information about how cores are being utilized\n",
    "    print(\"\\n\".join(sim.model.utilization_summary()))\n",
    "\n",
    "    sim.run(sim_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output data is a timeseries of the output values at each timestep.\n",
    "We compute the number of steps each example is shown for (`pres_steps`),\n",
    "and specify the number of steps we want to use for classification\n",
    "(`class_steps`, the last 30% of the presentation).\n",
    "We then reshape the output to index the presentation as the first dimension,\n",
    "and the timesteps in each presentation as the second dimension.\n",
    "We average over the last `class_steps` of each presentation,\n",
    "and take the `argmax` to figure out the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_steps = int(presentation_time / sim.dt)\n",
    "class_steps = int(0.3 * pres_steps)\n",
    "\n",
    "output = sim.data[output_p]\n",
    "output = output.reshape((n_images, pres_steps) + output[0].shape)\n",
    "output = output[:, -class_steps:].mean(axis=1)\n",
    "preds = np.argmax(output, axis=-1)\n",
    "\n",
    "assert preds.shape == test_y[:n_images].shape\n",
    "\n",
    "print(\"Predictions: %s\" % (list(preds),))\n",
    "print(\"Actual:      %s\" % (list(test_y[:n_images]),))\n",
    "error = (preds != test_y[:n_images]).mean()\n",
    "print(\"Accuracy: %0.3f%%, Error: %0.3f%%\" % (100 * (1 - error), 100 * error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we make a plot to show the network output over time for each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "images = test_x if channels_last else np.transpose(test_x, (0, 2, 3, 1))\n",
    "ni, nj, nc = images[0].shape\n",
    "allimage = np.zeros((ni, nj * n_images, nc))\n",
    "for i, image in enumerate(images[:n_images]):\n",
    "    allimage[:, i * nj : (i + 1) * nj] = image\n",
    "if allimage.shape[-1] == 1:\n",
    "    allimage = allimage[:, :, 0]\n",
    "allimage = (allimage + 1) / 2  # scale to [0, 1]\n",
    "plt.imshow(allimage, aspect=\"auto\", interpolation=\"none\", cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "t = sim.trange()\n",
    "plt.plot(t, sim.data[output_p])\n",
    "plt.xlim([t[0], t[-1]])\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.legend(label_names, loc=\"upper right\", bbox_to_anchor=(1.18, 1.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have successfully deployed the network we trained onto Loihi. As\n",
    "mentioned in the introduction, this is still a simplified example designed to fit on a\n",
    "single Loihi chip; we could achieve better performance with a larger model. But these\n",
    "same principles should apply to deploying any deep convolutional network onto Loihi."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
