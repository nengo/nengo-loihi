{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVS from file\n",
    "\n",
    "This example demonstrates how to load pre-recorded Dynamic Vision Sensor (DVS) event\n",
    "data from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import nengo\n",
    "import nengo_loihi\n",
    "\n",
    "# All NengoLoihi models should call this before model construction\n",
    "nengo_loihi.set_defaults()\n",
    "\n",
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data\n",
    "\n",
    "Rather than using real DVS data, we will generate some synthetic data and save it in a\n",
    "`.events` file. In most applications, this will not be necessary, since you will already\n",
    "have a `.events` or `.aedat` file from a real DVS camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter_time(n, t, jitter, rng, dtype=\"<u4\"):\n",
    "    assert jitter >= 0\n",
    "    assert t - jitter >= 0\n",
    "    tt = (t - jitter) * np.ones(n, dtype=dtype)\n",
    "    if jitter > 0:\n",
    "        tt += rng.randint(0, 2 * jitter + 1, size=tt.shape, dtype=dtype)\n",
    "    return tt\n",
    "\n",
    "\n",
    "# the height and width of the DVS sensor\n",
    "dvs_height = 180\n",
    "dvs_width = 240\n",
    "\n",
    "# our timestep in microseconds (Î¼s)\n",
    "dt_us = 1000\n",
    "\n",
    "# the maximum amount by which to jitter spikes around the timestep (in microseconds)\n",
    "t_jitter_us = 100\n",
    "\n",
    "assert t_jitter_us < dt_us // 2\n",
    "\n",
    "# the length of time to generate data for, in seconds and in microseconds\n",
    "t_length = 1.0\n",
    "t_length_us = int(1e6 * t_length)\n",
    "\n",
    "# the maximum rate of input spikes (per pixel)\n",
    "max_rate = 10\n",
    "max_prob = max_rate * 1e-6 * dt_us\n",
    "\n",
    "# the period of the sine wave, in pixels\n",
    "period = 120\n",
    "\n",
    "# these functions control the angle (theta) and phase of the sine wave over time\n",
    "theta_fn = lambda t: 1\n",
    "phase_fn = lambda t: 10 * t\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(-1, 1, dvs_width), np.linspace(-1, 1, dvs_height))\n",
    "\n",
    "events = []\n",
    "for t_us in range(dt_us, t_length_us + 1, dt_us):\n",
    "    t = t_us * 1e-6\n",
    "    theta = theta_fn(t)\n",
    "    phase = phase_fn(t)\n",
    "\n",
    "    X1 = np.cos(theta) * X + np.sin(theta) * Y\n",
    "\n",
    "    x = np.linspace(-1.5, 1.5, 50)\n",
    "    prob = np.sin((np.pi * dvs_height / period) * x + phase) * max_prob\n",
    "    prob = np.interp(X1, x, prob)\n",
    "\n",
    "    u = rng.rand(*prob.shape)\n",
    "    s_on = u < prob\n",
    "    s_off = u < -prob\n",
    "\n",
    "    y, x = s_off.nonzero()\n",
    "    tt = jitter_time(len(x), t_us, t_jitter_us, rng, dtype=\"<u4\")\n",
    "    events.append((tt, 0, x, y))\n",
    "\n",
    "    y, x = s_on.nonzero()\n",
    "    tt = jitter_time(len(x), t_us, t_jitter_us, rng, dtype=\"<u4\")\n",
    "    events.append((tt, 1, x, y))\n",
    "\n",
    "dvs_events = nengo_loihi.dvs.DVSEvents()\n",
    "dvs_events.init_events(n_events=sum(len(xx) for _, _, xx, _ in events))\n",
    "\n",
    "i = 0\n",
    "for tt, p, xx, yy in events:\n",
    "    ee = dvs_events.events[i : i + len(xx)]\n",
    "    ee[\"t\"] = tt\n",
    "    ee[\"p\"] = p\n",
    "    ee[\"x\"] = xx\n",
    "    ee[\"y\"] = yy\n",
    "    i += len(xx)\n",
    "\n",
    "events_file_name = \"dvs-from-file-events.events\"\n",
    "dvs_events.write_file(events_file_name)\n",
    "print(\"Wrote %r\" % events_file_name)\n",
    "del dvs_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the data by using the `DVSEvents` class to load the events, group the events\n",
    "into frames, and then make the frames into a video with the help of Matplotlib's\n",
    "animation support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs_events = nengo_loihi.dvs.DVSEvents.from_file(events_file_name)\n",
    "\n",
    "dt_frame_us = 20e3\n",
    "t_frames = dt_frame_us * np.arange(int(round(t_length_us / dt_frame_us)))\n",
    "\n",
    "fig = plt.figure()\n",
    "imgs = []\n",
    "for t_frame in t_frames:\n",
    "    t0_us = t_frame\n",
    "    t1_us = t_frame + dt_frame_us\n",
    "    t = dvs_events.events[:][\"t\"]\n",
    "    m = (t >= t0_us) & (t < t1_us)\n",
    "    events_m = dvs_events.events[m]\n",
    "\n",
    "    # show \"off\" (0) events as -1 and \"on\" (1) events as +1\n",
    "    events_sign = 2.0 * events_m[\"p\"] - 1\n",
    "\n",
    "    frame_img = np.zeros((dvs_height, dvs_width))\n",
    "    frame_img[events_m[\"y\"], events_m[\"x\"]] = events_sign\n",
    "\n",
    "    img = plt.imshow(frame_img, vmin=-1, vmax=1, animated=True)\n",
    "    imgs.append([img])\n",
    "\n",
    "del dvs_events\n",
    "\n",
    "ani = ArtistAnimation(fig, imgs, interval=50, blit=True)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nengo network\n",
    "\n",
    "We can now load our data into a NengoLoihi network, using the\n",
    "`nengo_loihi.DVSFileChipNode` type of `nengo.Node`. We pass the node the path to our\n",
    "data file. We also use the optional `pool` parameter to pool over space. This allows our\n",
    "node to output at a lower spatial resolution than the standard 180 x 240 pixel DVS\n",
    "output. We then make two ensembles: one to receive the positive polarity \"on\" events,\n",
    "and the other to receive the negative polarity \"off\" events. Since we passed\n",
    "`channels_last=True` to our node, the polarity will be the least-significant index of\n",
    "our node output, and we connect it to the ensembles accordingly (by sending all even\n",
    "outputs to the negative polarity ensemble `ensembles[0]`, and the odd outputs to the\n",
    "positive polarity ensemble `ensembles[1]`). We run the simulation and collect the spikes\n",
    "from both the negative and positive polarity ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = (10, 10)\n",
    "\n",
    "height = 180 // pool[0]\n",
    "width = 240 // pool[1]\n",
    "gain = 101\n",
    "\n",
    "with nengo.Network() as net:\n",
    "    u = nengo_loihi.DVSFileChipNode(\n",
    "        file_path=events_file_name, pool=pool, channels_last=True\n",
    "    )\n",
    "    assert u.height == height and u.width == width\n",
    "    assert u.polarity == 2\n",
    "\n",
    "    ensembles = [\n",
    "        nengo.Ensemble(\n",
    "            height * width,\n",
    "            1,\n",
    "            neuron_type=nengo.SpikingRectifiedLinear(),\n",
    "            gain=nengo.dists.Choice([gain]),\n",
    "            bias=nengo.dists.Choice([0]),\n",
    "        )\n",
    "        for _ in range(u.polarity)\n",
    "    ]\n",
    "\n",
    "    for k, e in enumerate(ensembles):\n",
    "        u_channel = u[k :: u.polarity]\n",
    "        nengo.Connection(u_channel, e.neurons, transform=1.0 / np.prod(pool))\n",
    "\n",
    "    probes = [nengo.Probe(e.neurons) for e in ensembles]\n",
    "\n",
    "with nengo_loihi.Simulator(net) as sim:\n",
    "    sim.run(t_length)\n",
    "\n",
    "sim_t = sim.trange()\n",
    "sim_nt = len(sim_t)\n",
    "output_spikes_neg = sim.data[probes[0]].reshape(sim_nt, height, width) * sim.dt\n",
    "output_spikes_pos = sim.data[probes[1]].reshape(sim_nt, height, width) * sim.dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot individual frames by collecting spikes near particular points in time.\n",
    "However, it is much easier to see how the output changes over time when we plot it as a\n",
    "video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_window = 0.02\n",
    "t_frames = np.linspace(0, 0.8, 5)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "rows, cols = len(t_frames), 1\n",
    "\n",
    "for k, t_frame in enumerate(t_frames):\n",
    "    t0 = t_frame\n",
    "    t1 = t_frame + t_window\n",
    "    m = (sim_t >= t0) & (sim_t < t1)\n",
    "\n",
    "    image = np.zeros((height, width))\n",
    "    image -= output_spikes_neg[m].sum(axis=0)\n",
    "    image += output_spikes_pos[m].sum(axis=0)\n",
    "    image = image / np.abs(image).max()\n",
    "\n",
    "    plt.subplot(rows, cols, k + 1)\n",
    "    plt.imshow(image, vmin=-1, vmax=1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"%0.2f <= t < %0.2f\" % (t0, t1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_frame = 0.01\n",
    "t_frames = dt_frame * np.arange(int(round(t_length / dt_frame)))\n",
    "\n",
    "fig = plt.figure()\n",
    "imgs = []\n",
    "for t_frame in t_frames:\n",
    "    t0 = t_frame\n",
    "    t1 = t_frame + dt_frame\n",
    "    m = (sim_t >= t0) & (sim_t < t1)\n",
    "\n",
    "    frame_img = np.zeros((height, width))\n",
    "    frame_img -= output_spikes_neg[m].sum(axis=0)\n",
    "    frame_img += output_spikes_pos[m].sum(axis=0)\n",
    "    frame_img = frame_img / np.abs(frame_img).max()\n",
    "\n",
    "    img = plt.imshow(frame_img, vmin=-1, vmax=1, animated=True)\n",
    "    imgs.append([img])\n",
    "\n",
    "ani = ArtistAnimation(fig, imgs, interval=50, blit=True)\n",
    "HTML(ani.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
