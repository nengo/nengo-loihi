{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting a Keras model to an SNN on Loihi\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nengo/nengo-dl/blob/master/docs/examples/keras-to-loihi.ipynb)\n",
    "\n",
    "This notebook describes how to train a network in Keras and convert it to a spiking neural network (SNN) to run on Loihi. Intel's Loihi chip is a type of \"neuromorphic\" hardwareâ€”specialized neural network acceleration hardware that uses spike-based communication like neurons in the brain. In this tutorial, will look at how to set up our network to target and run on Intel's Loihi chip using the NengoLoihi backend. While in general the Nengo ecosystem allows users to switch between backends without changes to their models, we will see how making some Loihi-specific changes during training and inference allow us to take full advantage of its capabilities.\n",
    "\n",
    "There are several ways to build SNNs to target NengoLoihi. The [CIFAR-10 Loihi example](https://www.nengo.ai/nengo-loihi/examples/cifar10-convnet.html) works through how to build up a deep spiking network to run on Loihi using the standard Nengo and NengoDL APIs. In NengoDL's [Keras to SNN example](https://www.nengo.ai/nengo-dl/examples/keras-to-snn.html), we looked at converting a Keras model to an SNN. Here, we will extend the Keras to SNN example, tailoring the model for execution on Loihi.\n",
    "\n",
    "The goal of this notebook is to familiarize you with some of the nuances of running SNNs on the Loihi, and how to set these up starting from a neural network defined in Keras. The two focuses in this notebook are on adding a network layer that runs off-chip to transform the input images into spikes, and training using a Loihi neuron model that captures the unique behaviour of Loihi's quantized neurons. We'll add the network layer and train and test with normal ReLU neurons first to see what kind of performance we can expect without quantization constraints. Then we'll train with the Loihi neurons to improve implementation performance, and finally we'll run the model on Loihi to measure the final performance (we use a simulated Loihi if actual Loihi hardware is not available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nengo\n",
    "import nengo_dl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import nengo_loihi\n",
    "\n",
    "# ignore NengoDL warning about no GPU\n",
    "warnings.filterwarnings(\"ignore\", message=\"No GPU\", module=\"nengo_dl\")\n",
    "\n",
    "# The results in this notebook should be reproducible across many random seeds.\n",
    "# However, some seed values may cause problems, particularly in the `to-spikes` layer\n",
    "# where poor initialization can result in no information being sent to the chip. We set\n",
    "# the seed to ensure that good results are reproducible without having to re-train.\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we'll use the standard [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in MNIST dataset\n",
    "(\n",
    "    (train_images, train_labels),\n",
    "    (test_images, test_labels),\n",
    ") = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# flatten images and add time dimension\n",
    "train_images = train_images.reshape((train_images.shape[0], 1, -1))\n",
    "train_labels = train_labels.reshape((train_labels.shape[0], 1, -1))\n",
    "test_images = test_images.reshape((test_images.shape[0], 1, -1))\n",
    "test_labels = test_labels.reshape((test_labels.shape[0], 1, -1))\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(np.reshape(train_images[i], (28, 28)), cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(str(train_labels[i, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the network\n",
    "\n",
    "We will start with the same network structure used in the [Keras to SNN example](https://www.nengo.ai/nengo-dl/examples/keras-to-snn.html): Two convolutional layers and a dense layer.\n",
    "\n",
    "The only way to communicate with the Loihi is by sending spikes. Usually, when we have a model that we want to run on neuromorphic hardware, we want the whole model that we've defined to run on the hardware. Communicating with Loihi, however, requires that we have at least one layer that runs *off*-chip to convert the input signal to spikes to send to the rest of the model running on Loihi.\n",
    "\n",
    "We'll add a `Conv2D` layer to run off-chip and convert the input signal to spikes. This could also be an `Activation` layer. The advantage to the `Activation` layer is that it adds no extra parameters and minimizes off-chip computations. The `Conv2D` layer uses a few parameters, and requires a bit more off-chip computation, but gives the network much more flexibility as to how pixels are converted to spikes. An `Activation` layer would likely work well for simple images like MNIST, but for more complex images (e.g. with more than one color channel, or a wider range of intensity values) the flexibility of the `Conv2D` layer is important. We avoid layers like the `Dense` layer, as it significantly increases both the number of parameters and the number of computations that have to be run off-chip.\n",
    "\n",
    "On the output side of the network, we now have to worry about how many neurons are in the last layer run on the chip. We are limited in how many neurons we can record from on the board, so we add a `Dense` layer with 100 neurons between the last `Conv2D` layer and our 10-dimensional `Dense` output layer (which runs off-chip). This way, we only have to record from 100 neurons, rather than the 2,304 neurons we would need to record from if we connected directly from the last `Conv2D` layer to the 10-dimensional output. An added benefit is that the amount of off-chip computation is reduced, since the number of weights used by the off-chip output layer is 100 x 10 instead of 2304 x 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.Input(shape=(28, 28, 1), name=\"input\")\n",
    "\n",
    "# transform input signal to spikes using trainable 1x1 convolutional layer\n",
    "to_spikes_layer = tf.keras.layers.Conv2D(\n",
    "    filters=3,  # 3 neurons per pixel\n",
    "    kernel_size=1,\n",
    "    strides=1,\n",
    "    activation=tf.nn.relu,\n",
    "    use_bias=False,\n",
    "    name=\"to-spikes\",\n",
    ")\n",
    "to_spikes = to_spikes_layer(inp)\n",
    "\n",
    "# on-chip convolutional layers\n",
    "conv0_layer = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    "    use_bias=False,\n",
    "    name=\"conv0\",\n",
    ")\n",
    "conv0 = conv0_layer(to_spikes)\n",
    "\n",
    "conv1_layer = tf.keras.layers.Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    activation=tf.nn.relu,\n",
    "    use_bias=False,\n",
    "    name=\"conv1\",\n",
    ")\n",
    "conv1 = conv1_layer(conv0)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten(name=\"flatten\")(conv1)\n",
    "\n",
    "dense0_layer = tf.keras.layers.Dense(units=100, activation=tf.nn.relu, name=\"dense0\")\n",
    "dense0 = dense0_layer(flatten)\n",
    "\n",
    "# since this final output layer has no activation function,\n",
    "# it will be converted to a `nengo.Node` and run off-chip\n",
    "dense1 = tf.keras.layers.Dense(units=10, name=\"dense1\")(dense0)\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=dense1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the networks\n",
    "\n",
    "As in the Keras-to-SNN notebook, once we create our model we'll use the NengoDL Converter to translate it into a Nengo network, and then we'll train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params_file=\"./keras_to_loihi_params\", epochs=1, **kwargs):\n",
    "    converter = nengo_dl.Converter(model, **kwargs)\n",
    "\n",
    "    with nengo_dl.Simulator(converter.net, seed=0, minibatch_size=200) as sim:\n",
    "        sim.compile(\n",
    "            optimizer=tf.optimizers.RMSprop(0.001),\n",
    "            loss={\n",
    "                converter.outputs[dense1]: tf.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True\n",
    "                )\n",
    "            },\n",
    "            metrics={converter.outputs[dense1]: tf.metrics.sparse_categorical_accuracy},\n",
    "        )\n",
    "        sim.fit(\n",
    "            {converter.inputs[inp]: train_images},\n",
    "            {converter.outputs[dense1]: train_labels},\n",
    "            epochs=epochs,\n",
    "        )\n",
    "\n",
    "        # save the parameters to file\n",
    "        sim.save_params(params_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train this network with normal ReLU neurons\n",
    "train(\n",
    "    epochs=2, swap_activations={tf.nn.relu: nengo.RectifiedLinear()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training for 2 epochs the non-spiking network achievs around 98% accuracy on the test data.\n",
    "\n",
    "Now that we have our trained weights, we can begin the conversion to spiking neurons. To help us in this process we're going to first define a helper function that will build the network for us, load weights from a specified file, and make it easy to play around with some other features of the network.\n",
    "\n",
    "### Evaluating the networks\n",
    "\n",
    "We will now define a general function to evaluate our network on the test dataset with various neural activation functions (both non-spiking and spiking). The function creates a new network with the desired activation function, loads the weights that we learned during training, runs the network on the test dataset, and reports accuracy and firing rate with both `print` statements and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(\n",
    "    activation,\n",
    "    params_file=\"./keras_to_loihi_params\",\n",
    "    n_steps=30,\n",
    "    scale_firing_rates=1,\n",
    "    synapse=None,\n",
    "    n_test=100,\n",
    "    n_plots=2,\n",
    "):\n",
    "    # convert the keras model to a nengo network\n",
    "    nengo_converter = nengo_dl.Converter(\n",
    "        model,\n",
    "        scale_firing_rates=scale_firing_rates,\n",
    "        swap_activations={tf.nn.relu: activation},\n",
    "        synapse=synapse,\n",
    "    )\n",
    "\n",
    "    # get input/output objects\n",
    "    nengo_input = nengo_converter.inputs[inp]\n",
    "    nengo_output = nengo_converter.outputs[dense1]\n",
    "\n",
    "    # add probes to layers to record activity\n",
    "    with nengo_converter.net:\n",
    "        probes = collections.OrderedDict(\n",
    "            [\n",
    "                [to_spikes_layer, nengo.Probe(nengo_converter.layers[to_spikes])],\n",
    "                [conv0_layer, nengo.Probe(nengo_converter.layers[conv0])],\n",
    "                [conv1_layer, nengo.Probe(nengo_converter.layers[conv1])],\n",
    "                [dense0_layer, nengo.Probe(nengo_converter.layers[dense0])],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # repeat inputs for some number of timesteps\n",
    "    tiled_test_images = np.tile(test_images[:n_test], (1, n_steps, 1))\n",
    "\n",
    "    # set some options to speed up simulation\n",
    "    with nengo_converter.net:\n",
    "        nengo_dl.configure_settings(stateful=False)\n",
    "\n",
    "    # build network, load in trained weights, run inference on test images\n",
    "    with nengo_dl.Simulator(\n",
    "        nengo_converter.net, minibatch_size=20, progress_bar=False\n",
    "    ) as nengo_sim:\n",
    "        nengo_sim.load_params(params_file)\n",
    "        data = nengo_sim.predict({nengo_input: tiled_test_images})\n",
    "\n",
    "    # compute accuracy on test data, using output of network on\n",
    "    # last timestep\n",
    "    test_predictions = np.argmax(data[nengo_output][:, -1], axis=-1)\n",
    "    print(\n",
    "        \"Test accuracy: %.2f%%\"\n",
    "        % (100 * np.mean(test_predictions == test_labels[:n_test, 0, 0]))\n",
    "    )\n",
    "\n",
    "    # plot the results\n",
    "    mean_rates = []\n",
    "    for i in range(n_plots):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(\"Input image\")\n",
    "        plt.imshow(test_images[i, 0].reshape((28, 28)), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        n_layers = len(probes)\n",
    "        mean_rates_i = []\n",
    "        for j, layer in enumerate(probes.keys()):\n",
    "            probe = probes[layer]\n",
    "            plt.subplot(n_layers, 3, (j * 3) + 2)\n",
    "            plt.suptitle(\"Neural activities\")\n",
    "\n",
    "            outputs = data[probe][i]\n",
    "\n",
    "            # look at only at non-zero outputs\n",
    "            nonzero = (outputs > 0).any(axis=0)\n",
    "            outputs = outputs[:, nonzero] if sum(nonzero) > 0 else outputs\n",
    "\n",
    "            # undo neuron amplitude to get real firing rates\n",
    "            outputs /= nengo_converter.layers[layer].ensemble.neuron_type.amplitude\n",
    "\n",
    "            rates = outputs.mean(axis=0)\n",
    "            mean_rate = rates.mean()\n",
    "            mean_rates_i.append(mean_rate)\n",
    "            print(\n",
    "                '\"%s\" mean firing rate (example %d): %0.1f' % (layer.name, i, mean_rate)\n",
    "            )\n",
    "\n",
    "            if is_spiking_type(activation):\n",
    "                outputs *= 0.001\n",
    "                plt.ylabel(\"# of Spikes\")\n",
    "            else:\n",
    "                plt.ylabel(\"Firing rates (Hz)\")\n",
    "\n",
    "            # plot outputs of first 100 neurons\n",
    "            plt.plot(outputs[:, :100])\n",
    "\n",
    "        mean_rates.append(mean_rates_i)\n",
    "\n",
    "        plt.xlabel(\"Timestep\")\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(\"Output predictions\")\n",
    "        plt.plot(tf.nn.softmax(data[nengo_output][i]))\n",
    "        plt.legend([str(j) for j in range(10)], loc=\"upper left\")\n",
    "        plt.xlabel(\"Timestep\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # take mean rates across all plotted examples\n",
    "    mean_rates = np.array(mean_rates).mean(axis=0)\n",
    "\n",
    "    return mean_rates\n",
    "\n",
    "\n",
    "def is_spiking_type(neuron_type):\n",
    "    return isinstance(neuron_type, (nengo.LIF, nengo.SpikingRectifiedLinear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test the trained networks on test set\n",
    "mean_rates = run_network(activation=nengo.RectifiedLinear(), n_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we're plotting the output over time for consistency with future plots, but since our network doesn't have any temporal elements (e.g. spiking neurons), the output is constant for each digit. The firing rates here displayed in the middle graph are important to note for conversion to spikes, and may vary somewhat depending on the random initial conditions used for training. One of the important features visible here, which we'll discuss shortly, is the decreasing mean firing rate as you move through the network. Note that these mean firing rates are computed across only the neurons that have non-zero activities; they are therefore the mean rates of the active neurons.\n",
    "\n",
    "Let's continue with the comparison by moving into spikes.\n",
    "\n",
    "## Converting to a spiking neural network\n",
    "\n",
    "Using the NengoDL converter, we can swap all the `relu` activation functions to `nengo.SpikingRectifiedLinear`. Using the lessons that we learned in the Keras->SNN example notebook we'll set `synapse=0.005` and `scale_firing_rates=100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test the trained networks using spiking neurons\n",
    "run_network(\n",
    "    activation=nengo.SpikingRectifiedLinear(), scale_firing_rates=100, synapse=0.005,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important feature of SNNs is the time required to generate output. The larger your scaling factor, the quicker the network response to input will be. This is because more spikes will be generated at each layer, triggering a quicker response at the succeeding layer.\n",
    "\n",
    "For still images, where each successive image has no correlation with the previous image, this leads to a lag in generating output. SNNs are however much more efficient in a problem like processing a video stream, where there is high correlation between frames. In general, SNNs perform better in situations with temporal dynamics. For simplicity, though, we only examine the case of processing still images here.\n",
    "\n",
    "Let's see what happens when we convert to an SNN using Loihi neurons.\n",
    "\n",
    "## Converting to SNN using Loihi neurons\n",
    "\n",
    "To get a sense of how well our network will run on Loihi, we switch to using the `LoihiSpikingRectifiedLinear` activation profile.\n",
    "\n",
    "Note that the on-chip restrictions don't apply to the input layer that we added to the network, because it won't be running on the Loihi. Here, the performance differences are minimal so we just convert all neurons over to Loihi neurons. If you find that adding the input layer is causing a performance drop, you may want to build your network such that only the on-chip layers use the NengoLoihi neurons and the off-chip layer uses a standard spiking neuron model (i.e. `SpikingRectifiedLinear`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the trained networks using spiking neurons\n",
    "run_network(\n",
    "    activation=nengo_loihi.neurons.LoihiSpikingRectifiedLinear(),\n",
    "    scale_firing_rates=100,\n",
    "    synapse=0.005,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training resulted a network with large differences between the firing rates (> 10Hz) of the network layers, switching to `LoihiSpikingRectifiedLinear` neurons will cause a significant decrease in the performance of the network. What causes this?\n",
    "\n",
    "Basically, the issue is that each of the layers need different scaling terms. With large firing rate discrepancies between layers, we end up trying to balance between having a `scale_firing_rate` value for the network that 1) is high enough to achieve good performance from the network, but 2) is low enough to not induce multiple spikes per time step in any layer. The second point here is where we're getting tripped up.\n",
    "\n",
    "Loihi neurons can only spike once per time step. Recall that while the `scale_firing_rates` term increases the gain on signals going into neurons, it also correspondingly decreases the `amplitude` of the neuron activity output. If `scale_firing_rates` is set high enough to expect three spikes per time step, but only one spike comes out, the effects will no longer balance out and performance will deteriorate.\n",
    "\n",
    "Instead of setting a single `scale_firing_rate` for the whole network, we can specify a scaling value for each layer. To figure out what range we want to put the firing rates into, let's look at the Loihi neurons' activation functions.\n",
    "\n",
    "### The Loihi activation profile\n",
    "\n",
    "The shape of the Loihi neuron activation profile is unique, and for high firing rates has strong discrepancies with standard `relu` and `lif` behaviour. This is due to the discretization required by the Loihi hardware. Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation(neurons, min, max, **kwargs):\n",
    "    x = np.arange(min, max, 0.001)\n",
    "    fr = neurons.rates(x=x, gain=[1], bias=[0])\n",
    "\n",
    "    plt.plot(x, fr, lw=2, **kwargs)\n",
    "    plt.title(\"%s with [gain=1, bias=0]\" % str(neurons))\n",
    "    plt.ylabel(\"Firing rate (Hz)\")\n",
    "    plt.xlabel(\"Input signal\")\n",
    "    plt.legend([\"Standard\", \"Loihi\"], loc=2)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plot_activation(nengo.RectifiedLinear(), -100, 1000)\n",
    "plot_activation(nengo_loihi.neurons.LoihiSpikingRectifiedLinear(), -100, 1000)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plot_activation(nengo.LIF(), -4, 40)\n",
    "plot_activation(nengo_loihi.neurons.LoihiLIF(), -4, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for lower firing rates the behaviour of the Loihi neurons approximates the normal `relu` and `lif` neurons relatively well, but for higher firing rates the discrepancy becomes larger. The discretization results in large plateus of input signal values where the output firing rate from the neuron stays the same, making different input values in this range indistinguishable. Also, as mentioned above, for input values above 1000 (not shown) the `LoihiSpikingRectifiedLinear` neuron will have a constant output of 1000 Hz (since this corresponds to one spike per timestep, the maximum firing rate on Loihi); the `SpikingRectifiedLinear` neuron, on the other hand, is able to fire faster than 1000 Hz by using multiple spikes per timestep.\n",
    "\n",
    "We can now return to our original question: How do we pick good firing rates for each layer? For outputs above 250 Hz, both Loihi activation functions show significant deviations from the non-Loihi activation profiles; they also become more discontinuous above this point. We therefore want to keep our maximum firing rates below 250 Hz. We also need the firing rate to be high enough to generate sufficient spikes, so that information can be transmitted from layer to layer in a reasonable time. For these reasons, we'll choose a target mean firing rate for each layer to be 200. We'll generate a scaling term for each layer individually to hit this target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = 200\n",
    "scale_firing_rates = {\n",
    "    to_spikes_layer: target_mean / mean_rates[0],\n",
    "    conv0_layer: target_mean / mean_rates[1],\n",
    "    conv1_layer: target_mean / mean_rates[2],\n",
    "    dense0_layer: target_mean / mean_rates[3],\n",
    "}\n",
    "\n",
    "# test the trained networks using spiking neurons\n",
    "run_network(\n",
    "    activation=nengo_loihi.neurons.LoihiSpikingRectifiedLinear(),\n",
    "    scale_firing_rates=scale_firing_rates,\n",
    "    synapse=0.005,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when we individually scale the activity of each layer, we almost fully recover non-spiking performance. Note that the firing rates of some layers (the later layers in particular) do not quite meet the target mean firing rate of 200 Hz, though. This is because our mean firing rates were measured using the `RectifiedLinear` neuron type, and do not account for the difference between it and the `LoihiSpikingRectifiedLinear` activation function. For better results, we could go back and measure the mean firing rates using the Loihi neuron type, or hand-tune the scaling factors on each layer to achieve the desired firing rates.\n",
    "\n",
    "Alternatively, we can train our network using the `LoihiSpikingRectifiedLinear`. This will account both for the discretization in the activation profile, and the hard limit of 1 spike per time step. For larger or more complex networks this can save time tuning.\n",
    "\n",
    "## Training with the Loihi neurons\n",
    "\n",
    "We're going to use another trick for training and set `scale_firing_rates=100` _while_ training. What this does essentially is initiate the network with high firing rates, such that during training we'll consistently find a local minima with higher firing rates that will work well when we swap in spiking neurons. It also reduces the discrepancy in firing rates between layers, starting them all off in a higher range.\n",
    "\n",
    "This is a low-overhead, ad-hoc means of increasing the firing rates of neurons in each layer, and does not guarantee that the network converges to a desired range of firing rates for each layer after training. The firing rate regularization methodâ€”shown in a basic form in the [Keras to SNN example](https://www.nengo.ai/nengo-dl/examples/keras-to-snn.html) and in a more powerful form in the [CIFAR-10 Loihi example](https://www.nengo.ai/nengo-loihi/examples/cifar10-convnet.html)â€”is a more consistent way to achieve the desired range of firing rates in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train this network with normal ReLU neurons\n",
    "train(\n",
    "    params_file=\"./keras_to_loihi_loihineuron_params\",\n",
    "    epochs=2,\n",
    "    swap_activations={tf.nn.relu: nengo_loihi.neurons.LoihiSpikingRectifiedLinear()},\n",
    "    scale_firing_rates=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we run the network we need to be sure to again set the `scale_firing_rates` parameter so that the training conditions are replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test the trained networks using spiking neurons\n",
    "run_network(\n",
    "    activation=nengo_loihi.neurons.LoihiSpikingRectifiedLinear(),\n",
    "    scale_firing_rates=100,\n",
    "    params_file=\"./keras_to_loihi_loihineuron_params\",\n",
    "    synapse=0.005,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another way that we can recover normal ReLU performance using Loihi neurons.\n",
    "\n",
    "As discussed in the [Keras to SNN example](https://www.nengo.ai/nengo-dl/examples/keras-to-snn.html), we can also train up this network using an extra term added to the loss function as a way of getting neurons into the desired range of firing rates. This method has the benefit of being more precise in the resultant firing rates of neurons in the network. When we set `scale_firing_rates` to a large number during training, we're simply instantiating the network with high firing rates and hoping it converges while maintaining these higher firing rates, but there is no guarantee. Adding the rate regularization term to the loss function ensures that the firing rates stay near their targets throughout the training process.\n",
    "\n",
    "## Running your SNN on Loihi\n",
    "\n",
    "At this point we're ready to test out our network on the Loihi. To actually run it on Loihi we have to set up a few more configuration parameters.\n",
    "\n",
    "We'll start by converting our network same as before, using the same parameters on the Converter call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_time = 0.03  # how long to present each input, in seconds\n",
    "n_test = 5  # how many images to test\n",
    "\n",
    "# convert the keras model to a nengo network\n",
    "nengo_converter = nengo_dl.Converter(\n",
    "    model,\n",
    "    scale_firing_rates=400,\n",
    "    swap_activations={tf.nn.relu: nengo_loihi.neurons.LoihiSpikingRectifiedLinear()},\n",
    "    synapse=0.005,\n",
    ")\n",
    "net = nengo_converter.net\n",
    "\n",
    "# get input/output objects\n",
    "nengo_input = nengo_converter.inputs[inp]\n",
    "nengo_output = nengo_converter.outputs[dense1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is load in the trained parameters. This involves creating a NengoDL Simulator, loading in the weights, and then calling the [`freeze_params`](https://www.nengo.ai/nengo-dl/reference.html#nengo_dl.Simulator.freeze_params) function to save the weights to the network object. This will then let us build a network with the trained weights inside the NengoLoihi Simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network, load in trained weights, save to network\n",
    "with nengo_dl.Simulator(net) as nengo_sim:\n",
    "    nengo_sim.load_params(\"keras_to_loihi_loihineuron_params\")\n",
    "    nengo_sim.freeze_params(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build the network in NengoLoihi we need to make a few more changes.\n",
    "\n",
    "The `input` Node needs to altered to generate our test images as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with net:\n",
    "    nengo_input.output = nengo.processes.PresentInput(\n",
    "        test_images, presentation_time=pres_time\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify that the `to_spikes` layer should run off-chip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with net:\n",
    "    nengo_loihi.add_params(net)  # allow on_chip to be set\n",
    "    net.config[nengo_converter.layers[to_spikes].ensemble].on_chip = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, if you try to build the network you will get an error\n",
    ">BuildError: Total synapse bits (1103808) exceeded max (1048576)\n",
    "\n",
    "which means that too many connections are going into a single Loihi core. To fix this, we need to specify the `block_shape` parameter on the convnet layers that are running on the Loihi. This lets us break up our convnet layer across multiple cores and prevent us from overloading a single core. The first parameter specifies the target size of the representation per core with a (`rows`, `columns`, `channels`) tuple. The max neurons per core is 1024, so `rows * columns * channels` must be less than 1024.\n",
    "\n",
    "The second parameter is the size of the full layer. This [can be calculated](https://en.wikipedia.org/wiki/Convolutional_neural_network#Convolutional_layer) with the `input_size`, `kernel_size`, `strides`, and `filters` parameters for the layer. We do this in the `calculate_size` function below.\n",
    "\n",
    "These parameters need to be tuned until the synapse and axon constraints are met. More details on `block_shape` can be found in the [`BlockShape` documentation](https://www.nengo.ai/nengo-loihi/api.html#nengo_loihi.BlockShape), with details about how to choose good block shapes in the [tips and tricks section](https://www.nengo.ai/nengo-loihi/tips.html#splitting-large-ensembles) of the documentation and in the [CIFAR-10 Loihi example](https://www.nengo.ai/nengo-loihi/examples/cifar10-convnet.html).\n",
    "\n",
    "For this example, we are using the `(16, 16, 4)` for `conv0`, `(8, 8, 16)` for `conv1`, and `(50,)` for our `dense0` (which breaks it up into two 50 neuron ensembles) to fit our model on Loihi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with net:\n",
    "    conv0_shape = conv0_layer.output_shape[1:]\n",
    "    net.config[\n",
    "        nengo_converter.layers[conv0].ensemble\n",
    "    ].block_shape = nengo_loihi.BlockShape((16, 16, 4), conv0_shape)\n",
    "\n",
    "    conv1_shape = conv1_layer.output_shape[1:]\n",
    "    net.config[\n",
    "        nengo_converter.layers[conv1].ensemble\n",
    "    ].block_shape = nengo_loihi.BlockShape((8, 8, 16), conv1_shape)\n",
    "\n",
    "    dense0_shape = dense0_layer.output_shape[1:]\n",
    "    net.config[\n",
    "        nengo_converter.layers[dense0].ensemble\n",
    "    ].block_shape = nengo_loihi.BlockShape((50,), dense0_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build the network and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NengoLoihi Simulator and run network\n",
    "with nengo_loihi.Simulator(net) as loihi_sim:\n",
    "    loihi_sim.run(n_test * pres_time)\n",
    "\n",
    "    # get output (last timestep of each presentation period)\n",
    "    pres_steps = int(round(pres_time / loihi_sim.dt))\n",
    "    output = loihi_sim.data[nengo_output][pres_steps - 1 :: pres_steps]\n",
    "\n",
    "    # compute the Loihi accuracy\n",
    "    loihi_predictions = np.argmax(output, axis=-1)\n",
    "    correct = 100 * np.mean(loihi_predictions == test_labels[:n_test, 0, 0])\n",
    "    print(\"Loihi accuracy: %.2f%%\" % correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy print-out is 100%, and we can also plot the results to see for ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the neural activity of the convnet layers\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "timesteps = loihi_sim.trange() / loihi_sim.dt\n",
    "\n",
    "# plot the presented MNIST digits\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "images = test_images.reshape(-1, 28, 28, 1)[:n_test]\n",
    "ni, nj, nc = images[0].shape\n",
    "allimage = np.zeros((ni, nj * n_test, nc), dtype=images.dtype)\n",
    "for i, image in enumerate(images[:n_test]):\n",
    "    allimage[:, i * nj : (i + 1) * nj] = image\n",
    "if allimage.shape[-1] == 1:\n",
    "    allimage = allimage[:, :, 0]\n",
    "plt.imshow(allimage, aspect=\"auto\", interpolation=\"none\", cmap=\"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# plot the network predictions\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(timesteps, loihi_sim.data[nengo_output])\n",
    "plt.legend([\"%d\" % i for i in range(10)], loc=\"lower left\")\n",
    "plt.suptitle(\"Output predictions\")\n",
    "plt.xlabel(\"Timestep\")\n",
    "plt.ylabel(\"Probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this example we've expanded on the process of converting a Keras model to an SNN with additional considerations that are important for SNN's we want to implement on the Loihi. We then showed the additional steps required to prepare a network generated by the NengoDL Converter to run on Loihi, including modifying the input node and specifying the distribution of convnet layers across cores."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
